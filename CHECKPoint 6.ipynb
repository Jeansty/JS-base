{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d969705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# importing required libraries\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import statistics\n",
    "import copy\n",
    "\n",
    "# set random seed\n",
    "random.seed('iris dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f0ef521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_csv(filename):\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = csv.reader(file)\n",
    "\t\treturn [row for row in csv_reader if row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe5519b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.reader??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f11c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_features(dataset):\n",
    "    num_columns = len(dataset[0])\n",
    "\n",
    "    for row in dataset:\n",
    "        for column in range(num_columns-1):\n",
    "            row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9a471d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_classes(dataset):\n",
    "    class_mappings = {}\n",
    "    for row in dataset:\n",
    "        _specie = row[-1]\n",
    "        if _specie not in class_mappings.keys():\n",
    "            class_mappings[_specie] = len(class_mappings)\n",
    "        row[-1] = class_mappings[_specie]\n",
    "\n",
    "    return class_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ae56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_data(dataset):\n",
    "    num_features = len(dataset[0])-1\n",
    "    for i in range(num_features):\n",
    "        column_values = [row[i] for row in dataset]\n",
    "        column_min = min(column_values)\n",
    "        column_max = max(column_values)\n",
    "        \n",
    "        for row in dataset:\n",
    "            row[i] = (row[i] - column_min) / (column_max - column_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8cb766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(filename):\n",
    "    dataset = _load_csv(filename)\n",
    "    _clean_features(dataset)\n",
    "    class_mappings = _map_classes(dataset)\n",
    "    _normalize_data(dataset)\n",
    "\n",
    "    return dataset, class_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c49dd8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "149cc345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    num_features = len(row1)-1\n",
    "\n",
    "    for i in range(num_features):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd9e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_k_neighbours(test_row, train_data, num_neighbours):\n",
    "    test_train_distances = []\n",
    "    for train_row in train_data:\n",
    "        _test_train_distance = _euclidean_distance(test_row, train_row)\n",
    "        test_train_distances.append([train_row, _test_train_distance])\n",
    "\n",
    "    test_train_distances.sort(key=lambda idx: idx[1])\n",
    "    return [test_train_distances[i][0] for i in range(num_neighbours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b105e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_classification(test_row, train_data, num_neighbours):\n",
    "    nearest_neighbours =  _get_k_neighbours(test_row, train_data, num_neighbours)\n",
    "    nearest_classes = [neighbour[-1] for neighbour in nearest_neighbours]\n",
    "    predicted_class = max(set(nearest_classes), key=nearest_classes.count)\n",
    "\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f4e56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_Algorithm(test_data, train_data, num_neighbours):\n",
    "    return [_predict_classification(test_row, train_data, num_neighbours) for test_row in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54db52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate kNN Algorithm\n",
    "\n",
    "def _test_train_split(dataset, test_ratio):\n",
    "    _dataset = copy.deepcopy(dataset)\n",
    "    random.shuffle(_dataset)\n",
    "\n",
    "    split_index = int(len(dataset) * test_ratio)\n",
    "    # Training data\n",
    "    test_sample = _dataset[0:split_index]\n",
    "    #Testing data\n",
    "    train_sample = _dataset[split_index:]\n",
    "\n",
    "    return test_sample, train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6542de50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_validation_split(dataset, num_groups):\n",
    "    dataset_groups = []\n",
    "    _dataset = copy.deepcopy(dataset)\n",
    "    group_size = int(len(_dataset) / num_groups)\n",
    "\n",
    "    for i in range(num_groups):\n",
    "        group = []\n",
    "        while len(group) < group_size:\n",
    "            idx = random.randrange(len(_dataset))\n",
    "            group.append(_dataset.pop(idx))\n",
    "        dataset_groups.append(group)\n",
    "\n",
    "    return dataset_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b23ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(test_sample, algorithm_predictions, class_mappings):\n",
    "    test_classes = [row[-1] for row in test_sample]\n",
    "    num_test_classes = len(test_classes)\n",
    "    test_labels = list(class_mappings.keys())\n",
    "\n",
    "    if len(test_classes) != len(algorithm_predictions):\n",
    "        raise IndexError(\"The count of test classes is not equal to the count of algorithm predictions!\")\n",
    "\n",
    "    num_correct_predictions = sum([actual == predicted for actual, predicted \n",
    "                                                        in zip(test_classes, algorithm_predictions)])\n",
    "\n",
    "    wrong_predictions = [f'A:{test_labels[actual]} | P:{test_labels[predicted]}'\n",
    "                                                            for actual, predicted \n",
    "                                                            in zip(test_classes, algorithm_predictions)\n",
    "                                                            if actual != predicted]\n",
    "                        \n",
    "    accuracy = (num_correct_predictions / num_test_classes) * 100\n",
    "    return accuracy, wrong_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6342b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts_Evaluate_kNN_Algorithm(dataset, class_mappings, test_ratio=0.25, \n",
    "                                                                num_neighbours=3, num_iterations=100):\n",
    "    \n",
    "    ACCURACY_HISTORY = []\n",
    "    WRONG_PREDICTION_HISTORY = []\n",
    "\n",
    "    for _iter in range(num_iterations):\n",
    "        _dataset = copy.deepcopy(dataset)\n",
    "        test_sample, train_sample = _test_train_split(_dataset, test_ratio)\n",
    "\n",
    "        algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n",
    "        accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n",
    "        ACCURACY_HISTORY.append(accuracy)\n",
    "        WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n",
    "\n",
    "    random.shuffle(WRONG_PREDICTION_HISTORY)\n",
    "    print('kNN algorithm evaluation using the Test/Train Split method:', '\\n\\t', \n",
    "                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n",
    "                'Maximum Accuracy:', max(ACCURACY_HISTORY), '\\n')\n",
    "\n",
    "    print('A: Actual | P: Predicted')\n",
    "    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8616e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvs_Evaluate_kNN_Algorithm(dataset, class_mappings, num_groups=5, \n",
    "                                                                num_neighbours=3, num_iterations=100):\n",
    "    \n",
    "    ACCURACY_HISTORY = []\n",
    "    WRONG_PREDICTION_HISTORY = []\n",
    "\n",
    "    for _iter in range(num_iterations):\n",
    "        _dataset = copy.deepcopy(dataset)\n",
    "        dataset_groups = _cross_validation_split(_dataset, num_groups)\n",
    "\n",
    "        for idx, group in enumerate(dataset_groups):\n",
    "            test_sample = group\n",
    "            _train_sample = copy.deepcopy(dataset_groups)\n",
    "            del _train_sample[idx]\n",
    "            \n",
    "            train_sample = []\n",
    "            for train_group in _train_sample:\n",
    "                train_sample.extend(train_group)\n",
    "\n",
    "            algorithm_predictions = kNN_Algorithm(test_sample, train_sample, num_neighbours)\n",
    "            accuracy, wrong_predictions = _get_accuracy(test_sample, algorithm_predictions, class_mappings)\n",
    "            ACCURACY_HISTORY.append(accuracy)\n",
    "            WRONG_PREDICTION_HISTORY.extend(wrong_predictions)\n",
    "\n",
    "    random.shuffle(WRONG_PREDICTION_HISTORY)\n",
    "    print('kNN algorithm evaluation using the Cross Validation Split method:', '\\n\\t', \n",
    "                'Average Accuracy:', round(statistics.mean(ACCURACY_HISTORY), ndigits=4), '\\n\\t', \n",
    "                'Maximum Accuracy:', max(ACCURACY_HISTORY),'\\n')\n",
    "\n",
    "    print('A: Actual | P: Predicted')\n",
    "    print('\\n'.join(WRONG_PREDICTION_HISTORY[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b153e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN algorithm evaluation using the Test/Train Split method: \n",
      "\t Average Accuracy: 0.027 \n",
      "\t Maximum Accuracy: 2.7027027027027026 \n",
      "\n",
      "A: Actual | P: Predicted\n",
      "A:6.7;3.1;5.6;2.4;Iris-virginica | P:5.4;3.7;1.5;0.2;Iris-setosa\n",
      "A:6.8;3.0;5.5;2.1;Iris-virginica | P:5.5;2.4;3.7;1.0;Iris-versicolor\n",
      "A:7.2;3.2;6.0;1.8;Iris-virginica | P:6.3;2.7;4.9;1.8;Iris-virginica\n",
      "A:7.2;3.2;6.0;1.8;Iris-virginica | P:5.0;3.6;1.4;0.2;Iris-setosa\n",
      "A:5.8;4.0;1.2;0.2;Iris-setosa | P:5.7;2.8;4.1;1.3;Iris-versicolor\n",
      "A:6.7;3.0;5.0;1.7;Iris-versicolor | P:6.7;3.1;4.4;1.4;Iris-versicolor\n",
      "A:4.9;2.5;4.5;1.7;Iris-virginica | P:5.5;2.5;4.0;1.3;Iris-versicolor\n",
      "A:6.2;3.4;5.4;2.3;Iris-virginica | P:6.1;3.0;4.6;1.4;Iris-versicolor\n",
      "A:7.7;2.8;6.7;2.0;Iris-virginica | P:7.2;3.6;6.1;2.5;Iris-virginica\n",
      "A:6.3;2.9;5.6;1.8;Iris-virginica | P:7.3;2.9;6.3;1.8;Iris-virginica\n",
      "A:5.2;4.1;1.5;0.1;Iris-setosa | P:5.2;2.7;3.9;1.4;Iris-versicolor\n",
      "A:5.4;3.9;1.3;0.4;Iris-setosa | P:4.9;3.1;1.5;0.1;Iris-setosa\n",
      "A:5.5;2.5;4.0;1.3;Iris-versicolor | P:5.6;2.8;4.9;2.0;Iris-virginica\n",
      "A:5.5;2.3;4.0;1.3;Iris-versicolor | P:5.1;3.3;1.7;0.5;Iris-setosa\n",
      "A:4.5;2.3;1.3;0.3;Iris-setosa | P:5.2;2.7;3.9;1.4;Iris-versicolor\n",
      "A:5.5;4.2;1.4;0.2;Iris-setosa | P:6.7;3.1;4.4;1.4;Iris-versicolor\n",
      "A:7.4;2.8;6.1;1.9;Iris-virginica | P:5.1;3.5;1.4;0.2;Iris-setosa\n",
      "A:4.9;3.1;1.5;0.1;Iris-setosa | P:5.1;3.5;1.4;0.2;Iris-setosa\n",
      "A:5.1;3.8;1.5;0.3;Iris-setosa | P:7.4;2.8;6.1;1.9;Iris-virginica\n",
      "A:5.0;2.3;3.3;1.0;Iris-versicolor | P:5.5;2.5;4.0;1.3;Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "#Evaluate kNN Algorithm: Using Test-Train Split Method\n",
    "dataset, class_mappings = DataLoader(r\"C:\\Users\\dofla\\Documents\\Python Scripts\\datasets\\iris.csv\")\n",
    "tts_Evaluate_kNN_Algorithm(dataset, class_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e48885c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN algorithm evaluation using the Cross Validation Split method: \n",
      "\t Average Accuracy: 0.0467 \n",
      "\t Maximum Accuracy: 6.666666666666667 \n",
      "\n",
      "A: Actual | P: Predicted\n",
      "A:5.7;2.8;4.1;1.3;Iris-versicolor | P:5.7;4.4;1.5;0.4;Iris-setosa\n",
      "A:6.5;2.8;4.6;1.5;Iris-versicolor | P:6.1;3.0;4.6;1.4;Iris-versicolor\n",
      "A:5.6;2.9;3.6;1.3;Iris-versicolor | P:6.1;3.0;4.6;1.4;Iris-versicolor\n",
      "A:7.4;2.8;6.1;1.9;Iris-virginica | P:5.2;4.1;1.5;0.1;Iris-setosa\n",
      "A:5.1;3.5;1.4;0.2;Iris-setosa | P:6.1;3.0;4.6;1.4;Iris-versicolor\n",
      "A:5.1;3.7;1.5;0.4;Iris-setosa | P:5.4;3.4;1.5;0.4;Iris-setosa\n",
      "A:6.0;2.2;4.0;1.0;Iris-versicolor | P:7.7;2.8;6.7;2.0;Iris-virginica\n",
      "A:6.2;3.4;5.4;2.3;Iris-virginica | P:5.7;3.8;1.7;0.3;Iris-setosa\n",
      "A:4.8;3.0;1.4;0.1;Iris-setosa | P:5.4;3.7;1.5;0.2;Iris-setosa\n",
      "A:5.4;3.7;1.5;0.2;Iris-setosa | P:6.5;3.0;5.2;2.0;Iris-virginica\n",
      "A:5.9;3.2;4.8;1.8;Iris-versicolor | P:6.4;2.9;4.3;1.3;Iris-versicolor\n",
      "A:5.8;2.7;5.1;1.9;Iris-virginica | P:6.3;3.4;5.6;2.4;Iris-virginica\n",
      "A:5.0;3.4;1.5;0.2;Iris-setosa | P:6.5;3.0;5.5;1.8;Iris-virginica\n",
      "A:5.1;3.8;1.6;0.2;Iris-setosa | P:6.4;3.2;4.5;1.5;Iris-versicolor\n",
      "A:6.1;3.0;4.6;1.4;Iris-versicolor | P:6.2;2.9;4.3;1.3;Iris-versicolor\n",
      "A:6.7;3.1;4.7;1.5;Iris-versicolor | P:5.7;4.4;1.5;0.4;Iris-setosa\n",
      "A:6.0;2.9;4.5;1.5;Iris-versicolor | P:5.4;3.9;1.3;0.4;Iris-setosa\n",
      "A:5.8;2.7;5.1;1.9;Iris-virginica | P:5.1;3.5;1.4;0.3;Iris-setosa\n",
      "A:6.2;2.9;4.3;1.3;Iris-versicolor | P:4.9;2.5;4.5;1.7;Iris-virginica\n",
      "A:5.5;2.3;4.0;1.3;Iris-versicolor | P:6.4;2.9;4.3;1.3;Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "#Evaluate kNN Algorithm: Using Cross-Validation Split Method\n",
    "dataset, class_mappings = DataLoader(r\"C:\\Users\\dofla\\Documents\\Python Scripts\\datasets\\iris.csv\")\n",
    "cvs_Evaluate_kNN_Algorithm(dataset, class_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c414e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
